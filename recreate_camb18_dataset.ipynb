{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** recreate camb18_dataset ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install\n",
    "#!pip install camb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory\n",
    "directory = 'camb18_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split up full-dataset as flow and fhigh \n",
    "\n",
    "# create flow and fhigh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split up TT_full as TT_flow and TT_fhigh\n",
    "TT_full_fname = 'TT_full.csv'\n",
    "TT_full       = pd.read_csv(directory + TT_full_fname)\n",
    "\n",
    "ns_As   = TT_full.iloc[:,0:2]\n",
    "\n",
    "TT_flow  = TT_full.iloc[:,2:30]\n",
    "TT_flow  = pd.concat([ns_As, TT_flow], axis=1)\n",
    "TT_flow.to_csv(directory + 'TT_flow.csv', index=False)\n",
    "\n",
    "TT_fhigh = TT_full.iloc[:,30:]\n",
    "TT_fhigh = pd.concat([ns_As, TT_fhigh], axis=1)\n",
    "TT_fhigh.to_csv(directory + 'TT_fhigh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split up TE_full as TE_flow and TE_fhigh\n",
    "TE_full_fname = 'TE_full.csv'\n",
    "TE_full       = pd.read_csv(directory + TE_full_fname)\n",
    "\n",
    "ns_As   = TE_full.iloc[:,0:2]\n",
    "\n",
    "TE_flow  = TE_full.iloc[:,2:30]\n",
    "TE_flow  = pd.concat([ns_As, TE_flow], axis=1)\n",
    "TE_flow.to_csv(directory + 'TE_flow.csv', index=False)\n",
    "\n",
    "TE_fhigh = TE_full.iloc[:,30:].copy()\n",
    "TE_fhigh = pd.concat([ns_As, TE_fhigh], axis=1)\n",
    "TE_fhigh.to_csv(directory + 'TE_fhigh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split up EE_full as EE_flow and EE_fhigh\n",
    "EE_full_fname = 'EE_full.csv'\n",
    "EE_full       = pd.read_csv(directory + EE_full_fname)\n",
    "\n",
    "ns_As   = EE_full.iloc[:,0:2]\n",
    "\n",
    "EE_flow  = EE_full.iloc[:,2:30]\n",
    "EE_flow  = pd.concat([ns_As, EE_flow], axis=1)\n",
    "EE_flow.to_csv(directory + 'EE_flow.csv', index=False)\n",
    "\n",
    "EE_fhigh = EE_full.iloc[:,30:].copy()\n",
    "EE_fhigh = pd.concat([ns_As, EE_fhigh], axis=1)\n",
    "EE_fhigh.to_csv(directory + 'EE_fhigh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the binned_high-$\\ell$ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_fhigh_fname = 'TT_fhigh.csv'\n",
    "TT_fhigh       = pd.read_csv(directory + TT_fhigh_fname)\n",
    "TE_fhigh_fname = 'TE_fhigh.csv'\n",
    "TE_fhigh       = pd.read_csv(directory + TE_fhigh_fname)\n",
    "EE_fhigh_fname = 'EE_fhigh.csv'\n",
    "EE_fhigh       = pd.read_csv(directory + EE_fhigh_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = TT_fhigh[['ns','As']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TT_fhigh = TT_fhigh.iloc[:,2:]\n",
    "df_TE_fhigh = TE_fhigh.iloc[:,2:]\n",
    "df_EE_fhigh = EE_fhigh.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_fhigh = []\n",
    "TE_fhigh = []\n",
    "EE_fhigh = []\n",
    "\n",
    "for i in range (len(df_TT_fhigh)):\n",
    "    TT_fhigh.append(df_TT_fhigh.iloc[i,:].values)\n",
    "\n",
    "for i in range (len(df_TE_fhigh)):\n",
    "    TE_fhigh.append(df_TE_fhigh.iloc[i,:].values)\n",
    "\n",
    "for i in range (len(df_EE_fhigh)):\n",
    "    EE_fhigh.append(df_EE_fhigh.iloc[i,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the binned fhigh dataset for camb15\n",
    "def binned(array, deltal, weights=1):\n",
    "    binned_array = []\n",
    "    n_bin        = int(len(array)/deltal) + 1  \n",
    "    for i in range(n_bin):\n",
    "        binn     = array[deltal*i:deltal*(i+1)]\n",
    "        average  = np.average(binn)\n",
    "        binned_array.append(average)\n",
    "    return binned_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_TT = np.arange(30, 2509)\n",
    "hl_TE = np.arange(30, 1997)\n",
    "hl_EE = np.arange(30, 1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltal = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dl_TE = []\n",
    "Dl_EE = []\n",
    "Dl_TT = []\n",
    "\n",
    "for i in range(len(TT_fhigh)):\n",
    "    Dl_TT.append(binned(TT_fhigh[i], deltal))\n",
    "TT_fhbinned = np.array(Dl_TT)\n",
    "\n",
    "\n",
    "for i in range(len(TE_fhigh)):\n",
    "    Dl_TE.append(binned(TE_fhigh[i], deltal))   \n",
    "TE_fhbinned = np.array(Dl_TE) \n",
    "\n",
    "\n",
    "for i in range(len(EE_fhigh)):\n",
    "    Dl_EE.append(binned(EE_fhigh[i], deltal))\n",
    "EE_fhbinned = np.array(Dl_EE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlb_TT = []\n",
    "hlb_TE = []\n",
    "hlb_EE = []\n",
    "\n",
    "for i in range(len(hl_TT)):\n",
    "    hlb_TT.append(binned(hl_TT, deltal))\n",
    "hlbinned_TT = np.array(hlb_TT).T\n",
    "\n",
    "for i in range(len(hl_TE)):\n",
    "    hlb_TE.append(binned(hl_TE, deltal))\n",
    "hlbinned_TE = np.array(hlb_TE).T\n",
    "\n",
    "for i in range(len(hl_EE)):\n",
    "    hlb_EE.append(binned(hl_EE, deltal))\n",
    "hlbinned_EE = np.array(hlb_EE).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TT = pd.DataFrame(TT_fhbinned, columns=list(map(str, hlbinned_TT[:,0])))\n",
    "df_TT = pd.concat([df_cp, df_TT],axis=1)\n",
    "\n",
    "df_TE = pd.DataFrame(TE_fhbinned, columns=list(map(str, hlbinned_TE[:,0])))\n",
    "df_TE = pd.concat([df_cp, df_TE],axis=1)\n",
    "\n",
    "df_EE = pd.DataFrame(EE_fhbinned, columns=list(map(str, hlbinned_EE[:,0])))\n",
    "df_EE = pd.concat([df_cp, df_EE],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TT.to_csv(directory + 'TT_fhigh_binned.csv', index=False)\n",
    "df_TE.to_csv(directory + 'TE_fhigh_binned.csv', index=False)\n",
    "df_EE.to_csv(directory + 'EE_fhigh_binned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the binned_full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_fl_fname = 'TT_flow.csv'\n",
    "TT_fl       = pd.read_csv(directory + TT_fl_fname)\n",
    "TE_fl_fname = 'TE_flow.csv'\n",
    "TE_fl       = pd.read_csv(directory + TE_fl_fname)\n",
    "EE_fl_fname = 'EE_flow.csv'\n",
    "EE_fl       = pd.read_csv(directory + EE_fl_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_bfh_fname = 'TT_fhigh_binned.csv'\n",
    "TT_bfh       =  pd.read_csv(directory + TT_bfh_fname).drop(['ns','As'], axis=1)\n",
    "TE_bfh_fname = 'TE_fhigh_binned.csv'\n",
    "TE_bfh       = pd.read_csv(directory + TE_bfh_fname).drop(['ns','As'], axis=1)\n",
    "EE_bfh_fname = 'EE_fhigh_binned.csv'\n",
    "EE_bfh       = pd.read_csv(directory + EE_bfh_fname).drop(['ns','As'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_ffull = pd.DataFrame()\n",
    "TE_ffull = pd.DataFrame()\n",
    "EE_ffull = pd.DataFrame()\n",
    "\n",
    "TT_ffull = pd.concat([TT_fl, TT_bfh], axis=1, sort='True')\n",
    "TE_ffull = pd.concat([TE_fl, TE_bfh], axis=1, sort='True')\n",
    "EE_ffull = pd.concat([EE_fl, EE_bfh], axis=1, sort='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_ffull.to_csv(directory + 'TT_full_binned.csv', index=False)\n",
    "TE_ffull.to_csv(directory + 'TE_full_binned.csv', index=False)\n",
    "EE_ffull.to_csv(directory + 'EE_full_binned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_bfh_fname = 'TT_fhigh_binned.csv'\n",
    "TT_bfh       =  pd.read_csv(directory + TT_bfh_fname)\n",
    "TE_bfh_fname = 'TE_fhigh_binned.csv'\n",
    "TE_bfh       = pd.read_csv(directory + TE_bfh_fname).drop(['ns','As'], axis=1)\n",
    "EE_bfh_fname = 'EE_fhigh_binned.csv'\n",
    "EE_bfh       = pd.read_csv(directory + EE_bfh_fname).drop(['ns','As'], axis=1)\n",
    "\n",
    "TE_ffull_fname = 'TE_full_binned.csv'\n",
    "TE_ffull = pd.read_csv(directory + TE_ffull_fname).drop(['ns','As'], axis=1)\n",
    "EE_ffull_fname = 'EE_full_binned.csv'\n",
    "EE_ffull = pd.read_csv(directory + EE_ffull_fname).drop(['ns','As'], axis=1)\n",
    "\n",
    "TE_fl_fname = 'TE_flow.csv'\n",
    "TE_fl       = pd.read_csv(directory + TE_fl_fname).drop(['ns','As'], axis=1)\n",
    "EE_fl_fname = 'EE_flow.csv'\n",
    "EE_fl       = pd.read_csv(directory + EE_fl_fname).drop(['ns','As'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTTEEE_bfh   = pd.DataFrame()\n",
    "TTTEEE_bfhf  = pd.DataFrame()\n",
    "TTTEEE_bfhfl = pd.DataFrame()\n",
    "\n",
    "TTTEEE_bfh   = pd.concat([TT_bfh, TE_bfh, EE_bfh],     axis=1, sort='True')\n",
    "TTTEEE_bfhf  = pd.concat([TT_bfh, TE_ffull, EE_ffull], axis=1, sort='True')\n",
    "TTTEEE_bfhfl = pd.concat([TT_bfh, TE_fl, EE_fl],       axis=1, sort='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTTEEE_bfh.to_csv(directory   + 'TT_fhigh_binned+TE_fhigh_binned+EE_fhigh_binned.csv', index=False)\n",
    "TTTEEE_bfhf.to_csv(directory  + 'TT_fhigh_binned+TE_full_binned+EE_full_binned.csv',   index=False)\n",
    "TTTEEE_bfhfl.to_csv(directory + 'TT_fhigh_binned+TE_flow+EE_flow.csv',                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_bfh_fname = 'TE_fhigh_binned.csv'\n",
    "TE_bfh       = pd.read_csv(directory + TE_bfh_fname).drop(['ns','As'], axis=1)\n",
    "EE_bfh_fname = 'EE_fhigh_binned.csv'\n",
    "EE_bfh       = pd.read_csv(directory + EE_bfh_fname).drop(['ns','As'], axis=1)\n",
    "\n",
    "TE_ffull_fname = 'TE_full_binned.csv'\n",
    "TE_ffull = pd.read_csv(directory + TE_ffull_fname)\n",
    "TE_ffull_fname = 'TE_full_binned.csv'\n",
    "TE_ffull = pd.read_csv(directory + TE_ffull_fname).drop(['ns','As'], axis=1)\n",
    "EE_ffull_fname = 'EE_full_binned.csv'\n",
    "EE_ffull = pd.read_csv(directory + EE_ffull_fname).drop(['ns','As'], axis=1)\n",
    "\n",
    "TE_fl_fname = 'TE_flow.csv'\n",
    "TE_fl       = pd.read_csv(directory + TE_fl_fname).drop(['ns','As'], axis=1)\n",
    "EE_fl_fname = 'EE_flow.csv'\n",
    "EE_fl       = pd.read_csv(directory + EE_fl_fname).drop(['ns','As'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTTEEE_ffull  = pd.DataFrame()\n",
    "TTTEEE_ffullh = pd.DataFrame()\n",
    "TTTEEE_ffulll = pd.DataFrame()\n",
    "\n",
    "TTTEEE_ffull  = pd.concat([TT_ffull, TE_ffull, EE_ffull], axis=1, sort='True')\n",
    "TTTEEE_ffullh = pd.concat([TT_ffull, TE_bfh, EE_bfh],     axis=1, sort='True')\n",
    "TTTEEE_ffulll = pd.concat([TT_ffull, TE_fl, EE_fl],       axis=1, sort='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTTEEE_ffull.to_csv(directory  + 'TT_full_binned+TE_full_binned+EE_full_binned.csv',   index=False)\n",
    "TTTEEE_ffullh.to_csv(directory + 'TT_full_binned+TE_fhigh_binned+EE_fhigh_binned.csv', index=False)\n",
    "TTTEEE_ffulll.to_csv(directory + 'TT_full_binned+TE_flow+EE_flow.csv',                 index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
